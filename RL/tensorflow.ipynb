{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow seperates defining computations and actually executing them. Builds up a computation graph and then executes it. Do the calculations it takes to get to a certain cell, which means skips steps that are useless! Can be easily parallellized by calculating different parts of the graph different computers/cores. Can visualize the graph by using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-02813be7fa4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## A tensor is basically a matrix. Scalar 0-dim, vector 1-dim, matrix 2-dim and so on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##adderar två tensorer och får en ny, 2 noder blir en ny nod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## får alltid här en default graf som sessionen är kopplad till, kan koppla till andra grafer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "## A tensor is basically a matrix. Scalar 0-dim, vector 1-dim, matrix 2-dim and so on\n",
    "\n",
    "a = tf.add(3,5) ##adderar två tensorer och får en ny, 2 noder blir en ny nod\n",
    "print(a) ## får alltid här en default graf som sessionen är kopplad till, kan koppla till andra grafer\n",
    "\n",
    "sess = tf.Session() ##gör beräkningarna via en en session\n",
    "x = sess.run(a)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625\n",
      "10\n",
      "15625\n",
      "Tensor(\"x_7:0\", shape=(), dtype=int32)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(2,name=\"x\")\n",
    "y = tf.constant(3,name=\"y\")\n",
    "\n",
    "op1 = tf.add(x,y)\n",
    "op2 = tf.multiply(x,y)\n",
    "op3 = tf.pow(op1,op2)\n",
    "useless = tf.add(op1,5) #don't need this to calculate op3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(op3))\n",
    "    a,b = sess.run([useless,op3])\n",
    "    print(a)\n",
    "    print(b)\n",
    "print(x)\n",
    "print((tf.Session()).run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  4.  9. 16. 25. 36.]\n",
      "Tensor(\"Mul_7:0\", shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a') ##i tensorboard ser nu vad noden heter\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
    "c = tf.multiply(a, b)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(c))\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph() #skapar en graf som inte är default grafen\n",
    "with g.as_default(): #sätter denna till våran aktuella graf!\n",
    "    x = tf.add(3,5)\n",
    "#sess = tf.Session() funkar ej!\n",
    "sess = tf.Session(graph=g)\n",
    "print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "# add ops to the default graph\n",
    "with g1.as_default():\n",
    "    a = tf.constant(3)\n",
    "# add ops to the user created graph\n",
    "with g2.as_default():\n",
    "    b = tf.constant(5)\n",
    "    c = tf.multiply(10,b)\n",
    "\n",
    "x = tf.add(5,a)\n",
    "sess = tf.Session()\n",
    "print(sess.run(x))\n",
    "sess = tf.Session(graph=g2)\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [4 4]]\n",
      "Tensor(\"Mul:0\", shape=(2, 2), dtype=int32)\n",
      "Tensor(\"Const:0\", shape=(2,), dtype=int32)\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([2,2])\n",
    "b = tf.constant([[1,1],[2,2]])\n",
    "x = tf.multiply(a,b)\n",
    "sess = tf.Session()\n",
    "print(sess.run(x))\n",
    "\n",
    "print(x)\n",
    "print(a)\n",
    "\n",
    "\n",
    "zeros = tf.zeros([5,6])\n",
    "print(sess.run(zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "s = tf.Variable(2,name=\"scalar\") ##en variable är ett objekt som innehåller en tensor. Kan ändra värde på den osv\n",
    "m = tf.Variable([[2,2],[0,6]],name=\"matrix\") ##dessa måste initialiseras. Om ej säger något så är trainable=True\n",
    "\n",
    "s = tf.get_variable(initializer=2,name=\"scalar\")\n",
    "m = tf.get_variable(initializer = tf.constant([[2,2],[2,2]]),name=\"matrix\")\n",
    "\n",
    "##kan skapa problem eftersom lägger till två noder med samma namn i default grafen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[-1.8095102   0.6290951  -0.01524934 ... -1.1078047  -1.0136828\n",
      "  -0.74618345]\n",
      " [-0.07681247 -0.84101135 -0.20427781 ... -0.2858144  -0.89496076\n",
      "   1.3322527 ]\n",
      " [-1.451832    0.26954365 -1.3570725  ...  0.49193954 -0.6717794\n",
      "   0.14656618]\n",
      " ...\n",
      " [ 1.1428466   0.5504437  -0.00874655 ...  0.6217006   1.3656809\n",
      "   0.14347461]\n",
      " [-0.09506294  0.03651287  1.1618186  ... -0.9578532  -0.1709638\n",
      "  -1.5856345 ]\n",
      " [-0.15315413 -0.16746192 -0.5821241  ... -0.08359166  0.59954834\n",
      "  -1.3612636 ]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([700, 10]))\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(W.initializer)) #notera när initialiserar den så får ingenting\n",
    "    print(W.eval())\n",
    "##efter använt en session så ska stänga den efter men med with så behövs det ej!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "W = tf.get_variable(initializer=10,name=\"W\")\n",
    "a = W.assign(100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(W.eval()) #prints 10\n",
    "    sess.run(a)\n",
    "    print(W.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable(2,name=\"my_var\")\n",
    "\n",
    "update = var.assign(2*var)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var.initializer)\n",
    "    print(var.eval())\n",
    "    sess.run(update)\n",
    "    print(var.eval())\n",
    "    sess.run(update)\n",
    "    print(var.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(10,name=\"my_var\")\n",
    "\n",
    "sess1 = tf.Session()\n",
    "sess2 = tf.Session()\n",
    "\n",
    "\n",
    "node1 = W.assign_add(10)\n",
    "node2 = W.assign_add(5)\n",
    "\n",
    "sess1.run(W.initializer)\n",
    "sess2.run(W.initializer)\n",
    "\n",
    "\n",
    "print(sess1.run(node1))\n",
    "print(sess2.run(node2)) #har två olika sessioner för samma graf. De har sina egna kopior av variablerna!\n",
    "\n",
    "sess1.close()\n",
    "sess2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "## en placeholder är en tensor som inte behöver ges något värde i början. Vi kan säga vad den ska \n",
    "# ha för värde efteråt när vi kör grafen i en session\n",
    "\n",
    "a = tf.placeholder(tf.float32,shape=[3])\n",
    "b = tf.constant([5,5,5],tf.float32)\n",
    "\n",
    "c = tf.add(a,b) #or a+b shortcut\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(c,feed_dict={a: [1,2,3]})\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 7. 8.]\n",
      "[10. 11. 12.]\n",
      "[11. 12. 10.]\n",
      "[10.  6.  7.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = tf.placeholder(tf.float32,shape=[3])\n",
    "b = tf.constant([5,5,5],tf.float32)\n",
    "\n",
    "c = tf.add(a,b) #or a+b shortcut\n",
    "\n",
    "vals = [[1,2,3],[5,6,7],[6,7,5],[5,1,2]]\n",
    "with tf.Session() as sess:\n",
    "    for val in vals:\n",
    "        res = sess.run(c,feed_dict={a: val})\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2]\n",
      "[3 3]\n"
     ]
    }
   ],
   "source": [
    "mat = tf.constant([[1,1,1],[1,1,1]],name=\"matrix\")\n",
    "n1 = tf.reduce_sum(mat,axis=0) #reducerar längsmed raderna\n",
    "n2 = tf.reduce_sum(mat,axis=1) #reducerar längsmed kolonnerna\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(n1))\n",
    "    print(sess.run(n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.86613655\n",
      "-1.285804\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "W = tf.Variable(3,name=\"W\",trainable=True,dtype=tf.float32)\n",
    "b = tf.Variable(-3,name=\"b\",trainable=True,dtype=tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "lin_model = W*x+b\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(y-lin_model))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss) #när kör denna noden så hittar gradienten och går i minus den\n",
    "                                    ## för alla trainable variabler!\n",
    "x_train = [0,1,2,3]\n",
    "y_train = [-1,-2,-3,-4]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(0,100):\n",
    "        sess.run(train,feed_dict={x:x_train,y:y_train})\n",
    "    print(W.eval())\n",
    "    print(b.eval())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9357\n",
      "[5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "y_train2 = np.zeros((10,60000))\n",
    "for ind,y in enumerate(y_train):\n",
    "    y_train2[y,ind] = 1\n",
    "y_train = y_train2\n",
    "\n",
    "y_test2 = np.zeros((10,10000))\n",
    "for ind,y in enumerate(y_test):\n",
    "    y_test2[y,ind] = 1\n",
    "y_test = y_test2\n",
    "\n",
    "\n",
    "plt.imshow(x_train[0],cmap=\"gray\")\n",
    "\n",
    "#normalizing data has enormous impact\n",
    "x_train2 = np.zeros((784,60000))\n",
    "for i in range(0,60000):\n",
    "    x = x_train[i]\n",
    "    x = np.ravel(x)/255\n",
    "    x_train2[:,i] = x\n",
    "x_train = x_train2\n",
    "\n",
    "x_test2 = np.zeros((784,10000))\n",
    "for i in range(0,10000):\n",
    "    x = x_test[i]\n",
    "    x = np.ravel(x)/255\n",
    "    x_test2[:,i] = x\n",
    "x_test = x_test2\n",
    "\n",
    "\n",
    "input = tf.placeholder(tf.float32,shape=[28*28,None])\n",
    "output = tf.placeholder(tf.float32,shape=[10,None])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal(shape=(500,28*28),stddev=0.1))\n",
    "b1 = tf.Variable(tf.ones([500,1]))*0.1\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal(shape=(10,500),stddev=0.1))\n",
    "b2 = tf.Variable(tf.ones([10,1]))*0.1\n",
    "\n",
    "h1 = tf.nn.sigmoid(tf.matmul(w1,input)+b1)\n",
    "h2 = tf.matmul(w2,h1)+b2\n",
    "res = tf.nn.softmax(h2,axis=0) ##får en matrix\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(res-output)) #no axis så summerar över alla!\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.07)\n",
    "\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "predict = tf.argmax(res,axis=0)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict,tf.argmax(output,axis=0)),tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(0,30000):\n",
    "        if (i+1) % 9000 == 0:\n",
    "            saver.save(sess,\"mnist\",global_step=i)\n",
    "        x = np.random.randint(0,60000)\n",
    "        sess.run(train,feed_dict={input:(x_train[:,x])[:,None],output:(y_train[:,x])[:,None]})\n",
    "    print(sess.run(accuracy,feed_dict={input:x_test,output:y_test}))\n",
    "    print(sess.run(predict,feed_dict={input:(x_test[:,23])[:,None]}))\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 340us/step - loss: 0.7053 - acc: 0.5340\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.7031 - acc: 0.5330\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.7034 - acc: 0.5350\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.7138 - acc: 0.4960\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.6962 - acc: 0.5260\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.6949 - acc: 0.5470\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.7020 - acc: 0.4950\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6955 - acc: 0.5070\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.6957 - acc: 0.5220\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6981 - acc: 0.5040\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6809 - acc: 0.5610\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.6959 - acc: 0.5190\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.6927 - acc: 0.5250\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.6941 - acc: 0.5260\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.6896 - acc: 0.5340\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.6930 - acc: 0.5260\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.6892 - acc: 0.5470\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.6933 - acc: 0.5110\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6928 - acc: 0.5180\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.6910 - acc: 0.5220\n",
      "100/100 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "##Keras sitter på tensorflow och underlätter användandet av NN. Finns två slags modeller:\n",
    "# Sequential och Functional. Sequential lägger på layer efter layer. Enkel.\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0460 - acc: 0.9843\n",
      "10000/10000 [==============================] - 1s 102us/step\n",
      "[0.028389572135731577, 0.990220001411438]\n"
     ]
    }
   ],
   "source": [
    "## Använder Functional model om flera input eller outputs (dvs vid olika ställen i NN) och\n",
    "## shared layer, dvs använder ett layer flera ggr\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "y_train2 = np.zeros((10,60000))\n",
    "for ind,y in enumerate(y_train):\n",
    "    y_train2[y,ind] = 1\n",
    "y_train = y_train2\n",
    "\n",
    "y_test2 = np.zeros((10,10000))\n",
    "for ind,y in enumerate(y_test):\n",
    "    y_test2[y,ind] = 1\n",
    "y_test = y_test2\n",
    "\n",
    "#normalizing data has enormous impact\n",
    "x_train2 = np.zeros((784,60000))\n",
    "for i in range(0,60000):\n",
    "    x = x_train[i]\n",
    "    x = np.ravel(x)/255\n",
    "    x_train2[:,i] = x\n",
    "x_train = x_train2\n",
    "\n",
    "x_test2 = np.zeros((784,10000))\n",
    "for i in range(0,10000):\n",
    "    x = x_test[i]\n",
    "    x = np.ravel(x)/255\n",
    "    x_test2[:,i] = x\n",
    "x_test = x_test2\n",
    "\n",
    "##i detta fall vill tydligen ha datan längsmed kolonnerna\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "input = Input(shape=(784,)) \n",
    "\n",
    "x = Dense(64,activation=\"relu\")(input)\n",
    "x = Dense(64,activation=\"relu\")(x)\n",
    "output = Dense(10,activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=input,outputs=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy']) ## när kompilerar så väljer vi loss och optimizer.\n",
    "model.fit(x_train,y_train) #här sker träningen! Kan välja batch size och ##epochs\n",
    "\n",
    "acc = model.evaluate(x_test,y_test)\n",
    "print(acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#shared layers!\n",
    "\n",
    "input = Input(shape=(784,))\n",
    "layer11 = Dense(64,activation=\"relu\")(input)\n",
    "layer12 = Dense(64,activation=\"relu\")(layer11)\n",
    "\n",
    "layer21 = Dense(64,activation=\"relu\")(input)\n",
    "layer = concatenate([layer12,layer21])\n",
    "\n",
    "final = Dense(1,activation=\"sigmoid\")(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Add\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "input1 = Input(shape=(784,))\n",
    "l1 = Dense(64,activation=\"relu\")(input1)\n",
    "\n",
    "input2 = Input(shape=(64,))\n",
    "layer = Add()([input2,l1])\n",
    "output = Dense(10,activation=\"softmax\")(layer)\n",
    "\n",
    "model = Model(inputs=[input1,input2],outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locvol(t,S):\n",
    "    return tf.sin(S)**2+t\n",
    "\n",
    "def stochasticvol(t):\n",
    "    return 1\n",
    "\n",
    "def map_operation1(row,spotp,strikep,dt):\n",
    "    endPrice = tf.scan(lambda a, x: a+stochasticvol(tf.cast(x[0],tf.float32)*dt)*locvol(tf.cast(x[0],tf.float32)*dt,a)*x[1],\n",
    "                   (tf.range(50),row),initializer=spotp)\n",
    "    return tf.maximum((endPrice-strikep),0.0)\n",
    "    \n",
    "def map_operation2(option):\n",
    "    strikep = option[0]\n",
    "    expiration = option[1]\n",
    "    spotp = option[2]\n",
    "    dt = expiration/tf.cast(N,tf.float32)\n",
    "    \n",
    "    mat = tf.random_normal(shape = (iterations,N), mean=0.0, stddev=tf.sqrt(dt), dtype=tf.float32)\n",
    "    map_result = tf.map_fn(lambda row : map_operation1(row,spotp,strikep,dt), mat, dtype=tf.float32)\n",
    "    return tf.reduce_mean(map_result)\n",
    "        \n",
    "        \n",
    "options = tf.constant([[0.9,0.5,1.0],[0.9,1.0,1.0],[1.0,0.5,1.0],\n",
    "                            [1.0,1.0,1.0],[1.1,0.5,1.0],[1.1,1.0,1.0],[1.0,0.75,1.0],[0.9,0.25,1.0]])\n",
    "N = tf.constant(50,dtype=tf.int32) #time discretization\n",
    "iterations = tf.constant(10**5)\n",
    "option_prices = tf.map_fn(map_operation2,options,dtype=tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(option_prices)\n",
    "    print(output)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
